{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning Project"
      ],
      "metadata": {
        "id": "oP1zJEwyRS_j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project aim to construct a tree predictor in order to predict either a mushroom is edible or poisonous. The github repository can be find here : https://github.com/theot-student/MachineLearning_Project"
      ],
      "metadata": {
        "id": "m5fl6RzBRY4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import random"
      ],
      "metadata": {
        "id": "rVV6_x75eANi"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "zQ27-DkyRiTG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this project we use the \"Secondary Mushrooms\" Dataset :\n",
        "Wagner,Dennis, Heider,D., and Hattab,Georges. (2023). Secondary Mushroom. UCI Machine Learning Repository. https://doi.org/10.24432/C5FP5Q."
      ],
      "metadata": {
        "id": "tuPb0q-vRlYW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxoK8D5-Qjxz",
        "outputId": "ec6d6bfe-cf99-4154-f306-abc739eec650"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ucimlrepo) (2.0.3)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.10/dist-packages (from ucimlrepo) (2024.6.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.7\n"
          ]
        }
      ],
      "source": [
        "!pip install ucimlrepo"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset has 20 features for each point."
      ],
      "metadata": {
        "id": "PgqC-WxbSM3K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "secondary_mushroom = fetch_ucirepo(id=848)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = secondary_mushroom.data.features\n",
        "y = secondary_mushroom.data.targets\n",
        "\n",
        "#we shuffle our data\n",
        "shuffleX = X.sample(frac=1)\n",
        "shuffleY = y.reindex(shuffleX.index)\n",
        "\n",
        "X_np = shuffleX.to_numpy()\n",
        "Y_np = shuffleY.to_numpy()\n",
        "\n",
        "# metadata\n",
        "print(secondary_mushroom.metadata)\n",
        "\n",
        "# variable information\n",
        "print(secondary_mushroom.variables)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-CbHXwiQu_i",
        "outputId": "b958ea66-38f0-4a55-8f17-a804abc59e58"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'uci_id': 848, 'name': 'Secondary Mushroom', 'repository_url': 'https://archive.ics.uci.edu/dataset/848/secondary+mushroom+dataset', 'data_url': 'https://archive.ics.uci.edu/static/public/848/data.csv', 'abstract': 'Dataset of simulated mushrooms for binary classification into edible and poisonous.', 'area': 'Biology', 'tasks': ['Classification'], 'characteristics': ['Tabular'], 'num_instances': 61068, 'num_features': 20, 'feature_types': ['Real'], 'demographics': [], 'target_col': ['class'], 'index_col': None, 'has_missing_values': 'yes', 'missing_values_symbol': 'NaN', 'year_of_dataset_creation': 2021, 'last_updated': 'Wed Apr 10 2024', 'dataset_doi': '10.24432/C5FP5Q', 'creators': ['Dennis Wagner', 'D. Heider', 'Georges Hattab'], 'intro_paper': {'title': 'Mushroom data creation, curation, and simulation to support classification tasks', 'authors': 'Dennis Wagner, D. Heider, Georges Hattab', 'published_in': 'Scientific Reports', 'year': 2021, 'url': 'https://www.semanticscholar.org/paper/336be248b6f1c5d77c3c93e89f2e19e7344b0250', 'doi': None}, 'additional_info': {'summary': 'The given information is about the Secondary Mushroom Dataset, the Primary Mushroom Dataset used for the simulation and the respective metadata can be found in the zip.\\n\\nThis dataset includes 61069 hypothetical mushrooms with caps based on 173 species (353 mushrooms\\nper species). Each mushroom is identified as definitely edible, definitely poisonous, or of\\nunknown edibility and not recommended (the latter class was combined with the poisonous class).\\n\\nThe related Python project contains a Python module secondary_data_generation.py\\nused to generate this data based on primary_data_edited.csv also found in the repository.\\nBoth nominal and metrical variables are a result of randomization.\\nThe simulated and ordered by species version is found in secondary_data_generated.csv.\\nThe randomly shuffled version is found in secondary_data_shuffled.csv.', 'purpose': 'Inspired by the Mushroom Data Set of J. Schlimmer: url:https://archive.ics.uci.edu/ml/datasets/Mushroom.', 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'One binary class divided in edible=e and poisonous=p (with the latter one also containing mushrooms of unknown edibility).\\nTwenty remaining variables (n: nominal, m: metrical)\\n1. cap-diameter (m): float number in cm\\n2. cap-shape (n): bell=b, conical=c, convex=x, flat=f,\\nsunken=s, spherical=p, others=o\\n3. cap-surface (n): fibrous=i, grooves=g, scaly=y, smooth=s,\\nshiny=h, leathery=l, silky=k, sticky=t,\\nwrinkled=w, fleshy=e\\n4. cap-color (n): brown=n, buff=b, gray=g, green=r, pink=p,\\npurple=u, red=e, white=w, yellow=y, blue=l,\\norange=o, black=k\\n5. does-bruise-bleed (n): bruises-or-bleeding=t,no=f\\n6. gill-attachment (n): adnate=a, adnexed=x, decurrent=d, free=e,\\nsinuate=s, pores=p, none=f, unknown=?\\n7. gill-spacing (n): close=c, distant=d, none=f\\n8. gill-color (n): see cap-color + none=f\\n9. stem-height (m): float number in cm\\n10. stem-width (m): float number in mm\\n11. stem-root (n): bulbous=b, swollen=s, club=c, cup=u, equal=e,\\nrhizomorphs=z, rooted=r\\n12. stem-surface (n): see cap-surface + none=f\\n13. stem-color (n): see cap-color + none=f\\n14. veil-type (n): partial=p, universal=u\\n15. veil-color (n): see cap-color + none=f\\n16. has-ring (n): ring=t, none=f\\n17. ring-type (n): cobwebby=c, evanescent=e, flaring=r, grooved=g,\\nlarge=l, pendant=p, sheathing=s, zone=z, scaly=y, movable=m, none=f, unknown=?\\n18. spore-print-color (n): see cap color\\n19. habitat (n): grasses=g, leaves=l, meadows=m, paths=p, heaths=h,\\nurban=u, waste=w, woods=d\\n20. season (n): spring=s, summer=u, autumn=a, winter=w', 'citation': None}}\n",
            "                    name     role         type demographic description units  \\\n",
            "0                  class   Target  Categorical        None        None  None   \n",
            "1           cap-diameter  Feature   Continuous        None        None  None   \n",
            "2              cap-shape  Feature  Categorical        None        None  None   \n",
            "3            cap-surface  Feature  Categorical        None        None  None   \n",
            "4              cap-color  Feature  Categorical        None        None  None   \n",
            "5   does-bruise-or-bleed  Feature  Categorical        None        None  None   \n",
            "6        gill-attachment  Feature  Categorical        None        None  None   \n",
            "7           gill-spacing  Feature  Categorical        None        None  None   \n",
            "8             gill-color  Feature  Categorical        None        None  None   \n",
            "9            stem-height  Feature   Continuous        None        None  None   \n",
            "10            stem-width  Feature   Continuous        None        None  None   \n",
            "11             stem-root  Feature  Categorical        None        None  None   \n",
            "12          stem-surface  Feature  Categorical        None        None  None   \n",
            "13            stem-color  Feature  Categorical        None        None  None   \n",
            "14             veil-type  Feature  Categorical        None        None  None   \n",
            "15            veil-color  Feature  Categorical        None        None  None   \n",
            "16              has-ring  Feature  Categorical        None        None  None   \n",
            "17             ring-type  Feature  Categorical        None        None  None   \n",
            "18     spore-print-color  Feature  Categorical        None        None  None   \n",
            "19               habitat  Feature  Categorical        None        None  None   \n",
            "20                season  Feature  Categorical        None        None  None   \n",
            "\n",
            "   missing_values  \n",
            "0              no  \n",
            "1              no  \n",
            "2              no  \n",
            "3             yes  \n",
            "4              no  \n",
            "5              no  \n",
            "6             yes  \n",
            "7             yes  \n",
            "8              no  \n",
            "9              no  \n",
            "10             no  \n",
            "11            yes  \n",
            "12            yes  \n",
            "13             no  \n",
            "14            yes  \n",
            "15            yes  \n",
            "16             no  \n",
            "17            yes  \n",
            "18            yes  \n",
            "19             no  \n",
            "20             no  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K-rxEKHldGEq"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The targets are used for binary classification with p if a mushroom is poisonous and e if it's edible"
      ],
      "metadata": {
        "id": "GRlXyz5-RPQl"
      }
    },
    {
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "y.groupby('class').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "Arjk9ExXSu0S",
        "outputId": "058f9a39-977f-419a-9df9-400714375297"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to split our dataSet in a training set and a test set"
      ],
      "metadata": {
        "id": "JBTxlASxnCqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nbDataTraining = int(len(X) * 0.8)"
      ],
      "metadata": {
        "id": "bsfAVivlRGsK"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nbDataTraining"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WoTynUsnmHl",
        "outputId": "b0c3769f-4cb4-42ab-bb82-916b2b3339dd"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48855"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_training = X_np[:nbDataTraining]\n",
        "Y_training = Y_np[:nbDataTraining]\n",
        "X_test = X_np[nbDataTraining:]\n",
        "Y_test = Y_np[nbDataTraining:]"
      ],
      "metadata": {
        "id": "S3saYifCooCa"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(Y_training, return_counts = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2Mh2G6029Sa",
        "outputId": "a0b7e5e1-305a-4add-d054-8709f9f3b25b"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['e', 'p'], dtype=object), array([21789, 27066]))"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tree predictor algorithm"
      ],
      "metadata": {
        "id": "kA5rLo1eTIM4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we need to define a node class to construct the tree"
      ],
      "metadata": {
        "id": "CwV0V1XOTMUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "  #Create a node for tree classifier\n",
        "  #\n",
        "  #VAR :\n",
        "  #     rightChildren, leftChildren : Node                    | childrens for the tree construction\n",
        "  #     isALeaf                     : Boolean                 | boolean to check if the node is a leaf\n",
        "  #     label                       : Integer/Char            | if the node is a leaf, this represents the label in which the datapoint in the nodes are classified\n",
        "  #     criterion                   : function                | if the node is not a leaf, this represents the criterion function to split the data points to the left and right children. It returns a boolean\n",
        "  #     criterionAlreadyUsed        : set<function>           | set of the criteria already used before in the tree\n",
        "  #     errorVariationDict          : dict<function, double>  | dictionnary keeping the variation error for every possible splitting of this leaf considering all criteria not already used before\n",
        "  #In our case, in a node, we consider that our right children contains always the result \"True\" to the criterion (i.e. that all the dataPoint that returns True with the criterion goes to the right children)\n",
        "\n",
        "\n",
        "  def __init__(self, rightChildren = None, leftChildren = None, isALeaf = None, label = None, criterion = None, criterionAlreadyUsed = set(), errorVariationDict = dict()):\n",
        "    self.rightChildren = rightChildren\n",
        "    self.leftChildren = leftChildren\n",
        "    self.isALeaf = isALeaf\n",
        "    self.label = label\n",
        "    self.criterion = criterion\n",
        "    self.criterionAlreadyUsed = criterionAlreadyUsed\n",
        "    self.errorVariationDict = errorVariationDict\n"
      ],
      "metadata": {
        "id": "A60CGQssTLw3"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BinaryTreePredictor:\n",
        "  #This class is used to train a tree predictor for a binary classification problem of machine learning. We will use a greedy (or greedy over all leaves) process to find the split at each iteration\n",
        "  #\n",
        "  #VAR :\n",
        "  #     decisionCriterionList : set                       | set of criterion possible over our features. Need to define what is a criterion, probably a function\n",
        "  #     splittingCriterion    : function                  | function to compute the training error and chose the best splitting reducing training error (phi function in lecture notes)\n",
        "  #     stoppingCriterion     : function                  | function that stop the grown of the tree (for exemple when the depth max is reached)\n",
        "  #     labels                : array                     | array containing all the possible labels\n",
        "  #     dictLeaves            : dict<Node, set<tuple>>    | dictionnary containing all the leaves as keys and the set of exemples rooted to this leaf as value\n",
        "  #     nbExemples            : integer                   | integer of the number of exemples\n",
        "  #     tree                  : Node                      | root of the tree classifier created by the algorithm\n",
        "\n",
        "  def __init__(self, decisionCriterionSet, splittingCriterion, stoppingCriterion):\n",
        "    self.decisionCriterionSet = decisionCriterionSet\n",
        "    self.splittingCriterion = splittingCriterion\n",
        "    self.stoppingCriterion = stoppingCriterion\n",
        "    self.labels = None\n",
        "    self.dictLeaves = None\n",
        "    self.nbExemples = None\n",
        "    self.tree = None\n",
        "\n",
        "  def leafTrainingError(self, leaf, dataPoints):\n",
        "    positifPoints = 0\n",
        "    nbPoint = len(dataPoints)\n",
        "    if nbPoint != 0:\n",
        "      for point in dataPoints:\n",
        "        if leaf.label == point[0]:\n",
        "          positifPoints += 1\n",
        "      if (positifPoints == 0):\n",
        "        return 10000\n",
        "      elif (positifPoints / nbPoint == 1):\n",
        "        return 0\n",
        "      else:\n",
        "        return self.splittingCriterion(positifPoints / nbPoint) * nbPoint\n",
        "    else:\n",
        "      return 10000\n",
        "\n",
        "  #not used anymore\n",
        "  def setLabel(self, leaf, dataPoints):\n",
        "    count0 = 0\n",
        "    count1 = 0\n",
        "\n",
        "    for point in dataPoints:\n",
        "      npPoint = np.array(point)\n",
        "      if npPoint[0] == self.labels[0]:\n",
        "        count0 += 1\n",
        "      else:\n",
        "        count1 += 1\n",
        "    if count1 < count0:\n",
        "      leaf.label = self.labels[0]\n",
        "    else:\n",
        "      leaf.label = self.labels[1]\n",
        "\n",
        "  def testSplit(self, leaf, criterion, points = None):\n",
        "    newRightLeaf = Node()\n",
        "    newLeftLeaf = Node()\n",
        "    rightPoints = set()\n",
        "    leftPoints = set()\n",
        "\n",
        "    if points == None:\n",
        "      points = self.dictLeaves[leaf]\n",
        "\n",
        "    countersRight = [0,0]\n",
        "    countersLeft = [0,0]\n",
        "\n",
        "    for point in points:\n",
        "      if criterion(np.array(point)):\n",
        "        rightPoints.add(point)\n",
        "        if point[0] == self.labels[0]:\n",
        "          countersRight[0] += 1\n",
        "        else:\n",
        "          countersRight[1] += 1\n",
        "      else:\n",
        "        leftPoints.add(point)\n",
        "        if point[0] == self.labels[0]:\n",
        "          countersLeft[0] += 1\n",
        "        else:\n",
        "          countersLeft[1] += 1\n",
        "\n",
        "    newRightLeaf.isALeaf = True\n",
        "    if countersRight[1] < countersRight[0]:\n",
        "      newRightLeaf.label = self.labels[0]\n",
        "    else:\n",
        "      newRightLeaf.label = self.labels[1]\n",
        "\n",
        "    newLeftLeaf.isALeaf = True\n",
        "    if countersRight[1] < countersRight[0]:\n",
        "      newLeftLeaf.label = self.labels[0]\n",
        "    else:\n",
        "      newLeftLeaf.label = self.labels[1]\n",
        "\n",
        "    errorVariation = self.leafTrainingError(leaf, points)\n",
        "    errorVariation -= self.leafTrainingError(newRightLeaf, rightPoints)\n",
        "    errorVariation -= self.leafTrainingError(newLeftLeaf, leftPoints)\n",
        "\n",
        "    return errorVariation\n",
        "\n",
        "  def calculVariationErrorDict(self,leaf, points = None):\n",
        "    errorVariationDict = dict()\n",
        "    for criterion in self.decisionCriterionSet:\n",
        "      if not(criterion in leaf.criterionAlreadyUsed):\n",
        "        errorVariationDict[criterion] = self.testSplit(leaf, criterion, points)\n",
        "      else:\n",
        "        errorVariationDict[criterion] = -100\n",
        "    return errorVariationDict\n",
        "\n",
        "\n",
        "  def splitLeaf(self, leaf, criterion):\n",
        "    newRightLeaf = Node()\n",
        "    newLeftLeaf = Node()\n",
        "    rightPoints = set()\n",
        "    leftPoints = set()\n",
        "\n",
        "    countersRight = [0,0]\n",
        "    countersLeft = [0,0]\n",
        "\n",
        "    for point in self.dictLeaves[leaf]:\n",
        "      if criterion(np.array(point)):\n",
        "        rightPoints.add(point)\n",
        "        if point[0] == self.labels[0]:\n",
        "          countersRight[0] += 1\n",
        "        else:\n",
        "          countersRight[1] += 1\n",
        "      else:\n",
        "        leftPoints.add(point)\n",
        "        if point[0] == self.labels[0]:\n",
        "          countersLeft[0] += 1\n",
        "        else:\n",
        "          countersLeft[1] += 1\n",
        "\n",
        "\n",
        "\n",
        "    newRightLeaf.isALeaf = True\n",
        "    if countersRight[1] < countersRight[0]:\n",
        "      newRightLeaf.label = self.labels[0]\n",
        "    else:\n",
        "      newRightLeaf.label = self.labels[1]\n",
        "    newRightLeaf.criterionAlreadyUsed = leaf.criterionAlreadyUsed.copy()\n",
        "    newRightLeaf.criterionAlreadyUsed.add(criterion)\n",
        "    newRightLeaf.errorVariationDict = self.calculVariationErrorDict(newRightLeaf, rightPoints)\n",
        "\n",
        "    newLeftLeaf.isALeaf = True\n",
        "    if countersRight[1] < countersRight[0]:\n",
        "      newLeftLeaf.label = self.labels[0]\n",
        "    else:\n",
        "      newLeftLeaf.label = self.labels[1]\n",
        "    newLeftLeaf.criterionAlreadyUsed = leaf.criterionAlreadyUsed.copy()\n",
        "    newLeftLeaf.criterionAlreadyUsed.add(criterion)\n",
        "    newLeftLeaf.errorVariationDict = self.calculVariationErrorDict(newLeftLeaf, leftPoints)\n",
        "\n",
        "    leaf.rightChildren = newRightLeaf\n",
        "    leaf.leftChildren = newLeftLeaf\n",
        "    leaf.isALeaf = False\n",
        "    leaf.label = None\n",
        "    leaf.criterion = criterion\n",
        "    leaf.errorVariationDict = dict()\n",
        "\n",
        "    self.dictLeaves.pop(leaf)\n",
        "    self.dictLeaves[newRightLeaf] = rightPoints\n",
        "    self.dictLeaves[newLeftLeaf] = leftPoints\n",
        "\n",
        "\n",
        "\n",
        "  def computeTrainingError(self):\n",
        "    trainingError = 0\n",
        "    for leaf in self.dictLeaves.keys():\n",
        "      trainingError += self.leafTrainingError(leaf, self.dictLeaves[leaf])\n",
        "    return (trainingError / self.nbExemples)\n",
        "\n",
        "\n",
        "  def growTree (self):\n",
        "    leafToSplit = None\n",
        "    criterionToUse = None\n",
        "    errorVariation = 0\n",
        "    for leaf in self.dictLeaves.keys():\n",
        "      for criterion in  leaf.errorVariationDict.keys():\n",
        "        if leaf.errorVariationDict[criterion] > errorVariation:\n",
        "          leafToSplit = leaf\n",
        "          criterionToUse = criterion\n",
        "          errorVariation = leaf.errorVariationDict[criterion]\n",
        "    if errorVariation != 0:\n",
        "      self.splitLeaf(leafToSplit, criterionToUse)\n",
        "    return errorVariation\n",
        "\n",
        "\n",
        "  def growAllLeaves (self):\n",
        "    totalErrorVariation = 0\n",
        "    for leaf in self.dictLeaves.copy().keys():\n",
        "      leafToSplit = None\n",
        "      criterionToUse = None\n",
        "      errorVariation = 0\n",
        "      for criterion in  leaf.errorVariationDict.keys():\n",
        "        if leaf.errorVariationDict[criterion] > errorVariation:\n",
        "          leafToSplit = leaf\n",
        "          criterionToUse = criterion\n",
        "          errorVariation = leaf.errorVariationDict[criterion]\n",
        "      if errorVariation > 0:\n",
        "        self.splitLeaf(leafToSplit, criterionToUse)\n",
        "        totalErrorVariation += errorVariation\n",
        "    return errorVariation\n",
        "\n",
        "  #data points are stored in np_array\n",
        "  def train(self, training_features, training_target, method = 'greedy'):\n",
        "    X = training_features\n",
        "    Y = training_target\n",
        "\n",
        "    self.nbExemples = len(X)\n",
        "    dataPoints = np.concatenate((Y, X),1)\n",
        "    dataPointsSet = set()\n",
        "    for point in dataPoints:\n",
        "      pointTuple = tuple(point)\n",
        "      dataPointsSet.add(pointTuple)\n",
        "\n",
        "    Y = Y.reshape(len(Y))\n",
        "    self.labels, counts = np.unique(Y, return_counts=True)\n",
        "    #init by a single node with the majority of class in the training set\n",
        "    majorityLabel = self.labels[np.argmax(counts)]\n",
        "    self.tree = Node(isALeaf = True, label = majorityLabel)\n",
        "\n",
        "    #we use a dict to store the datapoint in each leaves of our tree\n",
        "    self.dictLeaves = dict()\n",
        "    self.dictLeaves[self.tree] = dataPointsSet\n",
        "\n",
        "    trainingError = self.computeTrainingError()\n",
        "    print('training error = '+ str(trainingError))\n",
        "\n",
        "    self.tree.errorVariationDict = self.calculVariationErrorDict(self.tree)\n",
        "    variationError = 1\n",
        "    #then we have the loop to train the tree\n",
        "    while not(self.stoppingCriterion(self.tree, self.dictLeaves)) and (variationError > 0):\n",
        "      if method == 'greedy':\n",
        "        variationError = self.growTree()\n",
        "      if method == 'greedyAllLeaves':\n",
        "        variationError = self.growAllLeaves()\n",
        "      trainingError = self.computeTrainingError()\n",
        "      print('training error = '+ str(trainingError))\n",
        "\n",
        "  def treeDescent (self, point):\n",
        "    node = self.tree\n",
        "    while not(node.isALeaf):\n",
        "      if node.criterion(point):\n",
        "        node = node.rightChildren\n",
        "      else:\n",
        "        node = node.leftChildren\n",
        "    return node\n",
        "\n",
        "  def predict(self, point):\n",
        "    return self.treeDescent(point).label\n",
        "\n",
        "  def evaluateAccuracy(self, test_features, test_target):\n",
        "    rightExemples = 0\n",
        "    dataPoints = np.concatenate((test_target, test_features),1)\n",
        "    for i in range(len(test_features)):\n",
        "      label = self.predict(dataPoints[i])\n",
        "      if label == test_target[i]:\n",
        "        rightExemples +=1\n",
        "    return rightExemples / len(test_features)\n",
        "\n"
      ],
      "metadata": {
        "id": "buV3YWk5VJE1"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Criterion"
      ],
      "metadata": {
        "id": "TQzldTO1XzcB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definition CRITERION :\n",
        "function which take in input a set of dataPoint (i.e np.array)\n",
        "and which output a boolean\n",
        "should make a class for that"
      ],
      "metadata": {
        "id": "W63O5TG4Sk4U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to choose the criterion we can use to differientiate our features"
      ],
      "metadata": {
        "id": "hOr2XNvsX2Bj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(secondary_mushroom.variables[1:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JB1JUeVoVJne",
        "outputId": "4003f4cc-1c1d-487e-8a29-b4dfd13a2d1d"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                    name     role         type demographic description units  \\\n",
            "1           cap-diameter  Feature   Continuous        None        None  None   \n",
            "2              cap-shape  Feature  Categorical        None        None  None   \n",
            "3            cap-surface  Feature  Categorical        None        None  None   \n",
            "4              cap-color  Feature  Categorical        None        None  None   \n",
            "5   does-bruise-or-bleed  Feature  Categorical        None        None  None   \n",
            "6        gill-attachment  Feature  Categorical        None        None  None   \n",
            "7           gill-spacing  Feature  Categorical        None        None  None   \n",
            "8             gill-color  Feature  Categorical        None        None  None   \n",
            "9            stem-height  Feature   Continuous        None        None  None   \n",
            "10            stem-width  Feature   Continuous        None        None  None   \n",
            "11             stem-root  Feature  Categorical        None        None  None   \n",
            "12          stem-surface  Feature  Categorical        None        None  None   \n",
            "13            stem-color  Feature  Categorical        None        None  None   \n",
            "14             veil-type  Feature  Categorical        None        None  None   \n",
            "15            veil-color  Feature  Categorical        None        None  None   \n",
            "16              has-ring  Feature  Categorical        None        None  None   \n",
            "17             ring-type  Feature  Categorical        None        None  None   \n",
            "18     spore-print-color  Feature  Categorical        None        None  None   \n",
            "19               habitat  Feature  Categorical        None        None  None   \n",
            "20                season  Feature  Categorical        None        None  None   \n",
            "\n",
            "   missing_values  \n",
            "1              no  \n",
            "2              no  \n",
            "3             yes  \n",
            "4              no  \n",
            "5              no  \n",
            "6             yes  \n",
            "7             yes  \n",
            "8              no  \n",
            "9              no  \n",
            "10             no  \n",
            "11            yes  \n",
            "12            yes  \n",
            "13             no  \n",
            "14            yes  \n",
            "15            yes  \n",
            "16             no  \n",
            "17            yes  \n",
            "18            yes  \n",
            "19             no  \n",
            "20             no  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def unique_no_nan(x):\n",
        "    return x.dropna().unique()"
      ],
      "metadata": {
        "id": "v2deTO4PmE1N"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def createCategoricalSingleCriterion(X, featureIndex, featureName, criterionSet):\n",
        "  uniquesCategories = unique_no_nan(X[featureName])\n",
        "  halfCategory = len(uniquesCategories) // 2\n",
        "  setCategories = set()\n",
        "  for i in range(halfCategory):\n",
        "    setCategories.add(uniquesCategories[i])\n",
        "  def criterionFunction(x, featureIndex=featureIndex, setCategories=setCategories):\n",
        "      return x[featureIndex] in setCategories\n",
        "  criterionSet.add(criterionFunction)"
      ],
      "metadata": {
        "id": "EI7VuSiFiap8"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def createCategoricalSingleCriterions(X, featureIndex, featureName, criterionSet):\n",
        "  uniquesCategories = unique_no_nan(X[featureName])\n",
        "  for i in range(len(uniquesCategories)):\n",
        "    def criterionFunction(x, featureIndex=featureIndex, i=i):\n",
        "      return x[featureIndex] == uniquesCategories[i]\n",
        "    criterionSet.add(criterionFunction)"
      ],
      "metadata": {
        "id": "mFIZN-lIVHCm"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def createCategoricalPairCriterions(X, featureIndex, featureName, criterionSet):\n",
        "  uniquesCategories = unique_no_nan(X[featureName])\n",
        "  for i in range(len(uniquesCategories)-1):\n",
        "    def criterionFunction(x, featureIndex=featureIndex, i=i):\n",
        "      return (x[featureIndex] == uniquesCategories[i]) or (x[featureIndex] == uniquesCategories[i+1])\n",
        "    criterionSet.add(criterionFunction)"
      ],
      "metadata": {
        "id": "ZOgdAnRE8sr_"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterionSet = set()\n",
        "\n",
        "for index, feature in secondary_mushroom.variables[1:].iterrows():\n",
        "  if (feature.type == 'Categorical'):\n",
        "    createCategoricalSingleCriterions(X, index, feature['name'], criterionSet)"
      ],
      "metadata": {
        "id": "kbPIZDOOXrgz"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(criterionSet))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByreTlQi1X51",
        "outputId": "a52f6788-6e72-41d4-dca8-d9cd082ac71c"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now try to find good criterion for continous features"
      ],
      "metadata": {
        "id": "mvi_24uGU8LQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def continousCriterions(X, featureIndex, featureName, criterionSet, numberOfCriterions):\n",
        "  min = unique_no_nan(X[featureName]).min()\n",
        "  max = unique_no_nan(X[featureName]).max()\n",
        "  partition = np.linspace(min, max, numberOfCriterions)\n",
        "\n",
        "  for i in range(len(partition)-1):\n",
        "    def criterionFunction(x, featureIndex=featureIndex, i=i):\n",
        "      return ((partition[i] <= float(x[featureIndex])) and (float(x[featureIndex]) <= partition[i+1]))\n",
        "    criterionSet.add(criterionFunction)"
      ],
      "metadata": {
        "id": "unNzZasRU72O"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4gfW6sn9VBnT"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Splitting Criterion"
      ],
      "metadata": {
        "id": "lLRXnht3dci0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we use two differents splitting criterion (phi function in the lecture) :\n",
        "\n",
        "\n",
        "*  GiniIndex\n",
        "*  ScaledEntropy"
      ],
      "metadata": {
        "id": "d0-cWHOlPfpu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def giniIndex(p):\n",
        "  return 2*p*(1-p)"
      ],
      "metadata": {
        "id": "Bpw4mukZdgZU"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scaledEntropy(p):\n",
        "  return - ((p / 2) * math.log2(p) + ((1-p) / 2) * math.log2(1 - p))"
      ],
      "metadata": {
        "id": "Geh227hddt8a"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stop Criterion"
      ],
      "metadata": {
        "id": "DJXxDNj0efun"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we can say that the depth of the tree should not exceed a treshold"
      ],
      "metadata": {
        "id": "rR1NVPfJeoYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stopDepth(tree, depthMax):\n",
        "  if (depthMax == 0) and (tree.isALeaf):\n",
        "    return True\n",
        "  elif (depthMax != 0) and (tree.isALeaf):\n",
        "    return False\n",
        "  else:\n",
        "    if stopDepth(tree.rightChildren, depthMax-1):\n",
        "      return True\n",
        "    else:\n",
        "      return stopDepth(tree.leftChildren, depthMax-1)"
      ],
      "metadata": {
        "id": "m-GsCJ9Kei9N"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "But we can also stop whenever the new split does not contain enough point to be relevant."
      ],
      "metadata": {
        "id": "M_pDwsDQP2z8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stopHomogeneity(dictLeaves, nbPointMin):\n",
        "  for leaf in dictLeaves.keys():\n",
        "    if len(dictLeaves[leaf]) < nbPointMin:\n",
        "      return True\n",
        "  return False\n"
      ],
      "metadata": {
        "id": "-fZ_1VaRP2N_"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test on the dataSet"
      ],
      "metadata": {
        "id": "5p5D5PIWm2av"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) First test (dumb test)\n",
        "First we learn a first exemple for the tree with the following parameters:\n",
        "\n",
        "*   maximum depth = 5\n",
        "*   splitting critarion = gini Index\n",
        "*   for the Criterions of features, we use 1 criterion for each categorical feature\n"
      ],
      "metadata": {
        "id": "dmxrvaPA7Myv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "depthMax = 5"
      ],
      "metadata": {
        "id": "wxwEj4BH7Bjh"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "treePredictor1 = BinaryTreePredictor(criterionSet, giniIndex, lambda tree, dictLeaves : stopDepth(tree, depthMax))\n",
        "treePredictor1.train(X_training, Y_training)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_1o2CvzxyeS",
        "outputId": "7ab89ed6-4c71-46d0-e92e-90889b30e259"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training error = 0.3007225723187175\n",
            "training error = 0.2907574483364774\n",
            "training error = 0.27993957657955537\n",
            "training error = 0.27115239302556043\n",
            "training error = 0.263730716513133\n",
            "training error = 0.25823148368545606\n",
            "training error = 0.25444914110906697\n",
            "training error = 0.2506873801989549\n",
            "training error = 0.2471664679279027\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy1 = treePredictor1.evaluateAccuracy(X_test, Y_test)"
      ],
      "metadata": {
        "id": "552xrhx6zTxt"
      },
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy1 * 100"
      ],
      "metadata": {
        "id": "jjT4Yqs_zwEM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d266776-9a37-4f49-b7b0-36e33dcaf6c5"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38.06287866382839"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) Second test : comparing the splitting criterion\n",
        "We now use\n",
        "\n",
        "\n",
        "*   maximum depth = 4\n",
        "*   splitting critarion = gini Index\n",
        "*   for the Criterions of features, we use all pair of category in each categorical feature (the function is to see if the feature of the point belong to the pair)"
      ],
      "metadata": {
        "id": "DlFgBGNq8MMk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterionSet2 = set()\n",
        "\n",
        "for index, feature in secondary_mushroom.variables[1:].iterrows():\n",
        "  if (feature.type == 'Categorical'):\n",
        "    createCategoricalPairCriterions(X, index, feature['name'], criterionSet2)\n",
        "  elif (feature.type == 'Continuous'):\n",
        "    print()"
      ],
      "metadata": {
        "id": "WVyf02D0811n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75414690-d09a-46f0-9e4c-0d39b6947e33"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "depthMax2 = 4"
      ],
      "metadata": {
        "id": "5FO9zPUI872T"
      },
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "treePredictor2 = BinaryTreePredictor(criterionSet2, giniIndex, lambda tree, dictLeaves : stopDepth(tree, depthMax2))\n",
        "treePredictor2.train(X_training, Y_training)"
      ],
      "metadata": {
        "id": "2rshnKz10mLn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02dd7d31-de66-4e95-f8cf-b728d5adba86"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training error = 0.3007225723187175\n",
            "training error = 0.28856732591363954\n",
            "training error = 0.27584949909199674\n",
            "training error = 0.268246379146702\n",
            "training error = 0.26065984250671653\n",
            "training error = 0.2539235458509018\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = treePredictor2.evaluateAccuracy(X_test, Y_test)\n",
        "accuracy * 100"
      ],
      "metadata": {
        "id": "a8rCGc6J9HCJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af767b19-b051-4742-8cd4-4437f7ef8083"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55.853938103815295"
            ]
          },
          "metadata": {},
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "We keep the same parameters but change the splitting criterion by the scaled Entropy"
      ],
      "metadata": {
        "id": "Zs1eAioBCq6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "treePredictor3 = BinaryTreePredictor(criterionSet2, scaledEntropy, lambda tree, dictLeaves : stopDepth(tree, depthMax2))\n",
        "treePredictor3.train(X_training, Y_training)"
      ],
      "metadata": {
        "id": "iFCigYMnCwBK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba4cad01-c093-41be-b04e-f074fc895e6a"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training error = 0.30175907486879777\n",
            "training error = 0.288917688736122\n",
            "training error = 0.2794762168715445\n",
            "training error = 0.27266602601575635\n",
            "training error = 0.26604130043363816\n",
            "training error = 0.2605018701541382\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = treePredictor3.evaluateAccuracy(X_test, Y_test)\n",
        "accuracy * 100"
      ],
      "metadata": {
        "id": "sD0TBTwBHTUF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ed54a7e-7eda-405a-feb5-d9535251872a"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55.853938103815295"
            ]
          },
          "metadata": {},
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3) Third test : ading continuous criterion"
      ],
      "metadata": {
        "id": "GSL30EmACid1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterionSet4 = set()\n",
        "\n",
        "for index, feature in secondary_mushroom.variables[1:].iterrows():\n",
        "  if (feature.type == 'Categorical'):\n",
        "    createCategoricalSingleCriterions(X, index, feature['name'], criterionSet4)\n",
        "  elif (feature.type == 'Continuous'):\n",
        "    continousCriterions(X, index, feature['name'], criterionSet4, 4)"
      ],
      "metadata": {
        "id": "KOLb1PT_I6oK"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "treePredictor4 = BinaryTreePredictor(criterionSet4, giniIndex, lambda tree, dictLeaves : stopDepth(tree, 4))\n",
        "treePredictor4.train(X_training, Y_training, 'greedyAllLeaves')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qa51SEpJyAK",
        "outputId": "b5c38d86-7159-4b20-ed9b-c874a39ccf1c"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training error = 0.3007225723187175\n",
            "training error = 0.2907574483364774\n",
            "training error = 0.27251790006712806\n",
            "training error = 0.25618661302663187\n",
            "training error = 0.24147025291814128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy4 = treePredictor4.evaluateAccuracy(X_test, Y_test)\n",
        "accuracy4 * 100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gf5PJhVCJ78F",
        "outputId": "6f700b8f-d917-483b-a07d-41ebe928f71b"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60.537088586867526"
            ]
          },
          "metadata": {},
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4) Fourth test : we compare the two growing method\n",
        "We now use\n",
        "\n",
        "\n",
        "*   minimum homogeneity = 50\n",
        "*   splitting critarion = gini Index\n",
        "*   for the criteria of features, we use a single criterion of category in each categorical feature and 4 criteria for continuous features\n",
        "\n",
        "We want to see the differences of the two methods for growing the tree"
      ],
      "metadata": {
        "id": "i0OcaTIgbwnN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterionSet5 = set()\n",
        "\n",
        "for index, feature in secondary_mushroom.variables[1:].iterrows():\n",
        "  if (feature.type == 'Categorical'):\n",
        "    createCategoricalSingleCriterions(X, index, feature['name'], criterionSet5)\n",
        "  elif (feature.type == 'Continuous'):\n",
        "    continousCriterions(X, index, feature['name'], criterionSet5, 4)"
      ],
      "metadata": {
        "id": "FTsOzNAObv-F"
      },
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "treePredictor5 = BinaryTreePredictor(criterionSet5, giniIndex, lambda tree, dictLeaves : stopHomogeneity(dictLeaves, 50))\n",
        "treePredictor5.train(X_training, Y_training, 'greedyAllLeaves')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UO0_XL6CZLXT",
        "outputId": "d75b1c8f-b9e2-4d8e-9b5c-30ca31f31eb4"
      },
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training error = 0.27547132222229087\n",
            "training error = 0.2663355436677719\n",
            "training error = 0.2550878439953288\n",
            "training error = 0.24610190826580483\n",
            "training error = 0.23160118687634032\n",
            "training error = 0.21892336082980182\n",
            "training error = 0.2049584944175781\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy5 = treePredictor5.evaluateAccuracy(X_test, Y_test)\n",
        "accuracy5 * 100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYc3vaQxcA-c",
        "outputId": "fc12be89-3f71-46ba-9a27-5598461657b9"
      },
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44.62911413132471"
            ]
          },
          "metadata": {},
          "execution_count": 244
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterionSet6 = criterionSet5\n",
        "treePredictor6 = BinaryTreePredictor(criterionSet6, giniIndex, lambda tree, dictLeaves : stopHomogeneity(dictLeaves, 50))\n",
        "treePredictor6.train(X_training, Y_training)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUXauw2adHmT",
        "outputId": "7d686c6e-0cc6-44b8-bae2-e8a1e9cfe468"
      },
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training error = 0.27547132222229087\n",
            "training error = 0.2663355436677719\n",
            "training error = 0.25901450247258256\n",
            "training error = 0.25320797039729914\n",
            "training error = 0.24565035956570527\n",
            "training error = 0.24131570825856585\n",
            "training error = 0.23738904978131203\n",
            "training error = 0.23351803562126336\n",
            "training error = 0.2303386319670229\n",
            "training error = 0.2273916554166941\n",
            "training error = 0.22373556528830604\n",
            "training error = 0.2211271060375748\n",
            "training error = 0.21871279257956042\n",
            "training error = 0.21636863742992624\n",
            "training error = 0.21297503731977838\n",
            "training error = 0.21061647507127093\n",
            "training error = 0.20835239258665164\n",
            "training error = 0.2061360899466385\n",
            "training error = 0.2039247341161523\n",
            "training error = 0.2014419805820458\n",
            "training error = 0.1991196599354932\n",
            "training error = 0.19696252623335356\n",
            "training error = 0.19498025462113033\n",
            "training error = 0.19309853161137241\n",
            "training error = 0.19144039123147139\n",
            "training error = 0.18947883803199733\n",
            "training error = 0.1874241190702184\n",
            "training error = 0.1857629737402075\n",
            "training error = 0.18420367687947\n",
            "training error = 0.18267156525681483\n",
            "training error = 0.1811604025428486\n",
            "training error = 0.17829054895544807\n",
            "training error = 0.17673917017785226\n",
            "training error = 0.17534522706232486\n",
            "training error = 0.1740993068574878\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy6 = treePredictor5.evaluateAccuracy(X_test, Y_test)\n",
        "accuracy6 * 100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pvnY0OYe7wz",
        "outputId": "30f6e793-7059-42c4-e6a9-6c4aca498342"
      },
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44.62911413132471"
            ]
          },
          "metadata": {},
          "execution_count": 246
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5) Fifth test : a more classical and reasonnable test\n"
      ],
      "metadata": {
        "id": "iNjz0I7sjIuU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   maximum depth = 8\n",
        "*   splitting critarion = gini Index\n",
        "*   for the Criterions of features, we use every single criterion for each categorical feature, and 2 criterion for continuous features\n",
        "*greedyAllLeaves"
      ],
      "metadata": {
        "id": "WNKYJ0E5JaOW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterionSet7 = set()\n",
        "\n",
        "for index, feature in secondary_mushroom.variables[1:].iterrows():\n",
        "  if (feature.type == 'Categorical'):\n",
        "    createCategoricalSingleCriterions(X, index, feature['name'], criterionSet7)\n",
        "  elif (feature.type == 'Continuous'):\n",
        "    continousCriterions(X, index, feature['name'], criterionSet7, 2)"
      ],
      "metadata": {
        "id": "ca3Fy9dwfAZ6"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "treePredictor7 = BinaryTreePredictor(criterionSet7, giniIndex, lambda tree, dictLeaves : stopDepth(tree, 8))\n",
        "treePredictor7.train(X_training, Y_training, 'greedyAllLeaves')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaMNeSi5jLr6",
        "outputId": "9f9a928b-3797-4963-b6bc-baef09e10bbf"
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training error = 0.3007225723187175\n",
            "training error = 0.2907574483364774\n",
            "training error = 0.27251790006712806\n",
            "training error = 0.25618661302663187\n",
            "training error = 0.24147025291814128\n",
            "training error = 0.22377857904331233\n",
            "training error = 0.20959656155516665\n",
            "training error = 0.19888968413160507\n",
            "training error = 0.1883673553154743\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy7 = treePredictor7.evaluateAccuracy(X_test, Y_test)\n",
        "accuracy7 * 100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsGeNbcbjYx_",
        "outputId": "28f629ba-cb43-4438-f0d9-4a5f6a740e06"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "71.81922384149337"
            ]
          },
          "metadata": {},
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6) best computation for now\n",
        "These parameters are the best I have tested for now :\n",
        "\n",
        "\n",
        "*   maximum depth = 20\n",
        "*   splitting critarion = gini Index\n",
        "*   for the Criterions of features, we use every single criterion for each categorical feature, and 2 criterion for continuous features"
      ],
      "metadata": {
        "id": "NYQ7oPWkR1C-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterionSet8 = set()\n",
        "\n",
        "for index, feature in secondary_mushroom.variables[1:].iterrows():\n",
        "  if (feature.type == 'Categorical'):\n",
        "    createCategoricalSingleCriterions(X, index, feature['name'], criterionSet8)\n",
        "  elif (feature.type == 'Continuous'):\n",
        "    continousCriterions(X, index, feature['name'], criterionSet8, 2)"
      ],
      "metadata": {
        "id": "h4eGaCxfotCL"
      },
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "treePredictor8 = BinaryTreePredictor(criterionSet8, giniIndex, lambda tree, dictLeaves : stopDepth(tree, 20))\n",
        "treePredictor8.train(X_training, Y_training, 'greedyAllLeaves')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0lz6VOL-CcT",
        "outputId": "9464d392-0960-433d-bfa1-5483f4e5f887"
      },
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training error = 0.3007225723187175\n",
            "training error = 0.2907574483364774\n",
            "training error = 0.27251790006712806\n",
            "training error = 0.25618661302663187\n",
            "training error = 0.24147025291814128\n",
            "training error = 0.22377857904331233\n",
            "training error = 0.20959656155516665\n",
            "training error = 0.19888968413160507\n",
            "training error = 0.1883673553154743\n",
            "training error = 0.16915463439532563\n",
            "training error = 0.14807203815631934\n",
            "training error = 0.1347273575481141\n",
            "training error = 0.12065153752145351\n",
            "training error = 0.11053594458641317\n",
            "training error = 0.09980902681870607\n",
            "training error = 0.08964795985659388\n",
            "training error = 0.08167213649962635\n",
            "training error = 0.07510797243386541\n",
            "training error = 0.07067242098655667\n",
            "training error = 0.06678438049249037\n",
            "training error = 0.0637211015227694\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy8 = treePredictor8.evaluateAccuracy(X_test, Y_test)\n",
        "accuracy8 * 100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2LwmAfWJQ-l",
        "outputId": "123e9efb-4712-4b50-87af-2398809ab10c"
      },
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "94.2197478303586"
            ]
          },
          "metadata": {},
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest"
      ],
      "metadata": {
        "id": "MJR3R81xBid4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To compute random forest, we need to things :\n",
        "\n",
        "\n",
        "1.   create some subset of our training set by sampling over the rows and the columns (we remove some feature to construct each tree)\n",
        "2.    train tree over all this subset and do a majority vote\n"
      ],
      "metadata": {
        "id": "GSg7F8h8Br48"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cb36KAh_G3o2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RandomForest:\n",
        "\n",
        "  def __init__(self, decisionCriterionSet, splittingCriterion, stoppingCriterion, numberOfTrees):\n",
        "    self.decisionCriterionSet = decisionCriterionSet\n",
        "    self.splittingCriterion = splittingCriterion\n",
        "    self.stoppingCriterion = stoppingCriterion\n",
        "    self.numberOfTrees = numberOfTrees\n",
        "\n",
        "  def samplingData(self, training_features, training_target, decisionCriterionSet):\n",
        "\n",
        "    #first we take a proportion of our exemples\n",
        "    #we chose that 67% of the datas are sampled which is the choice indicate in the google random forest course\n",
        "    proba = 0.67\n",
        "    nbExemplesSample = int(self.nbExemples * proba)\n",
        "    training_features_sample = training_features[0:nbExemplesSample]\n",
        "    training_target_sample =training_target[0:nbExemplesSample]\n",
        "    for i in range(nbExemplesSample):\n",
        "      rand = random.randint(0,self.nbExemples-1)\n",
        "      training_features_sample[i] = training_features[rand]\n",
        "      training_target_sample[i] = training_target[rand]\n",
        "\n",
        "    #we now need to extract a random number of feature from this data.\n",
        "    #A lazy way to do that (sorry I run out of time for this project) is to change every exemple of this features by a constant value (for exemple the first exemple value)\n",
        "    #then when splitting the feature will never be considered as a good split\n",
        "\n",
        "    nbFeatureDeleted = random.randint(self.nbFeatures//2,self.nbFeatures-2)\n",
        "    featuresDeleted = random.sample(np.linspace(0,self.nbFeatures-1,self.nbFeatures,dtype=int).tolist(), nbFeatureDeleted)\n",
        "    xTemp = training_features_sample[0]\n",
        "\n",
        "    for x in training_features_sample:\n",
        "      for j in featuresDeleted:\n",
        "        x[j] = xTemp[j]\n",
        "\n",
        "    return training_features_sample, training_target_sample, decisionCriterionSet\n",
        "\n",
        "  def computeTrainingError(self):\n",
        "    trainingError = 0\n",
        "    for tree in self.forest:\n",
        "      trainingError += tree.computeTrainingError()\n",
        "    return trainingError / self.numberOfTrees\n",
        "\n",
        "  def createForest(self,training_features, training_target, method = 'greedy'):\n",
        "    self.forest = set()\n",
        "    self.nbExemples = len(training_features)\n",
        "    self.nbFeatures = len(training_features[1])\n",
        "\n",
        "    for k in range(self.numberOfTrees):\n",
        "      print('tree ' + str(k) + ' :')\n",
        "      print()\n",
        "      training_features_sample, training_target_sample, decisionCriterionSet = self.samplingData(training_features, training_target, self.decisionCriterionSet)\n",
        "      tree = BinaryTreePredictor(decisionCriterionSet, self.splittingCriterion, self.stoppingCriterion)\n",
        "      tree.train(training_features_sample,training_target_sample, method)\n",
        "      self.forest.add(tree)\n",
        "\n",
        "    print(self.computeTrainingError())\n",
        "\n",
        "  def predict(self,point):\n",
        "    predictions = []\n",
        "    for tree in self.forest:\n",
        "      label = tree.predict(point)\n",
        "      predictions += label\n",
        "    labels, count = np.unique(np.array(predictions), return_counts=True)\n",
        "    return labels[np.argmax(count)]\n",
        "\n",
        "  def evaluateAccuracy(self, test_features, test_target):pecies\n",
        "    testError = 0\n",
        "    dataPoints = np.concatenate((test_target, test_features),1)\n",
        "    for i in range(len(test_features)):\n",
        "      label = self.predict(dataPoints[i])\n",
        "      if label == test_target[i]:\n",
        "        testError +=1\n",
        "    return testError / len(test_features)"
      ],
      "metadata": {
        "id": "O0OsiUdRBkQd"
      },
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterionSetForest1 = set()\n",
        "\n",
        "for index, feature in secondary_mushroom.variables[1:].iterrows():\n",
        "  if (feature.type == 'Categorical'):\n",
        "    createCategoricalSingleCriterions(X, index, feature['name'], criterionSetForest1)\n",
        "  elif (feature.type == 'Continuous'):\n",
        "    continousCriterions(X, index, feature['name'], criterionSetForest1, 2)"
      ],
      "metadata": {
        "id": "51aTciHTNr8U"
      },
      "execution_count": 248,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RandomForest1 = RandomForest(criterionSetForest1, giniIndex,  lambda tree, dictLeaves : stopDepth(tree, 5), 21)\n",
        "RandomForest1.createForest(X_training, Y_training, 'greedyAllLeaves')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OupDl6TNs6t",
        "outputId": "cec3722b-d537-4f33-f70e-d67677c2ba66"
      },
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tree 0 :\n",
            "\n",
            "training error = 0.0034488552802909313\n",
            "training error = 0.0033518621510276684\n",
            "training error = 0.003234615713426716\n",
            "training error = 0.003117472360781284\n",
            "training error = 0.0030339519183424524\n",
            "training error = 0.002913659941869902\n",
            "tree 1 :\n",
            "\n",
            "training error = 0.10230582962187366\n",
            "training error = 0.09914122835907781\n",
            "training error = 0.09618536358851264\n",
            "training error = 0.09329238828113322\n",
            "training error = 0.08969952899379416\n",
            "training error = 0.08608216694682996\n",
            "tree 2 :\n",
            "\n",
            "training error = 0.0883991886824102\n",
            "training error = 0.08672513894205225\n",
            "training error = 0.08537297463024622\n",
            "training error = 0.08358552886725809\n",
            "training error = 0.08239751504370356\n",
            "training error = 0.08051168741823847\n",
            "tree 3 :\n",
            "\n",
            "training error = 0.11094791045608084\n",
            "training error = 0.10702005034423671\n",
            "training error = 0.10131461253728394\n",
            "training error = 0.09448122711176773\n",
            "training error = 0.0888604694111718\n",
            "training error = 0.08309243876194407\n",
            "tree 4 :\n",
            "\n",
            "training error = 0.08689930095913521\n",
            "training error = 0.08532176124540347\n",
            "training error = 0.08397748972864917\n",
            "training error = 0.0828605242416888\n",
            "training error = 0.08222804689056785\n",
            "training error = 0.08159832538284188\n",
            "tree 5 :\n",
            "\n",
            "training error = 0.16211905075249813\n",
            "training error = 0.1588199599832051\n",
            "training error = 0.1560896335307603\n",
            "training error = 0.15084131333372916\n",
            "training error = 0.1460756781812826\n",
            "training error = 0.13918482358858997\n",
            "tree 6 :\n",
            "\n",
            "training error = 0.004300944747951023\n",
            "training error = 0.004170612239794988\n",
            "training error = 0.00402558160363147\n",
            "training error = 0.0038571416590588332\n",
            "training error = 0.0037129482506755864\n",
            "training error = 0.003573194189410736\n",
            "tree 7 :\n",
            "\n",
            "training error = 0.11625925607379298\n",
            "training error = 0.11145345975855084\n",
            "training error = 0.10656132756263607\n",
            "training error = 0.09852962054579426\n",
            "training error = 0.091592169484524\n",
            "training error = 0.08525410754168597\n",
            "tree 8 :\n",
            "\n",
            "training error = 0.058947977319499814\n",
            "training error = 0.05655192754209007\n",
            "training error = 0.0555526176171023\n",
            "training error = 0.055028065504056076\n",
            "training error = 0.054822809966352595\n",
            "training error = 0.054687103588787464\n",
            "tree 9 :\n",
            "\n",
            "training error = 0.1194949217855966\n",
            "training error = 0.11488482952647795\n",
            "training error = 0.10838367588602066\n",
            "training error = 0.10331075660024469\n",
            "training error = 0.09856738536693961\n",
            "training error = 0.09215316633119218\n",
            "tree 10 :\n",
            "\n",
            "training error = 0.006797292765004918\n",
            "training error = 0.006536671554849485\n",
            "training error = 0.006383132479154721\n",
            "training error = 0.006221532747053135\n",
            "training error = 0.0060625068643390045\n",
            "training error = 0.005950844911830116\n",
            "tree 11 :\n",
            "\n",
            "training error = 0.01654288202217328\n",
            "training error = 0.015933343171185544\n",
            "training error = 0.015569648740506458\n",
            "training error = 0.015187657204785227\n",
            "training error = 0.014795876516466648\n",
            "training error = 0.014429177213660495\n",
            "tree 12 :\n",
            "\n",
            "training error = 0.11362649711799394\n",
            "training error = 0.11010739943266798\n",
            "training error = 0.10714121550864465\n",
            "training error = 0.10365705087063666\n",
            "training error = 0.10035940672876607\n",
            "training error = 0.09353686490523135\n",
            "tree 13 :\n",
            "\n",
            "training error = 0.06368697633203274\n",
            "training error = 0.06284043761100742\n",
            "training error = 0.0621983777530703\n",
            "training error = 0.06157834557823757\n",
            "training error = 0.061241156615957214\n",
            "training error = 0.06100368537895039\n",
            "tree 14 :\n",
            "\n",
            "training error = 0.0985267785172317\n",
            "training error = 0.09695310381103896\n",
            "training error = 0.09449637183963461\n",
            "training error = 0.09261030322260284\n",
            "training error = 0.09070029138927478\n",
            "training error = 0.08738563315070567\n",
            "tree 15 :\n",
            "\n",
            "training error = 0.0004999277882083699\n",
            "training error = 0.0004424648240464882\n",
            "training error = 0.0004118746633716694\n",
            "training error = 0.0003897452907595887\n",
            "training error = 0.0003688648481769008\n",
            "training error = 0.0003577029614240906\n",
            "tree 16 :\n",
            "\n",
            "training error = 0.11208159301201584\n",
            "training error = 0.10908196024518889\n",
            "training error = 0.10244418602508373\n",
            "training error = 0.10006049032741744\n",
            "training error = 0.09616149378665623\n",
            "training error = 0.09241072013796865\n",
            "tree 17 :\n",
            "\n",
            "training error = 0.14261595746219313\n",
            "training error = 0.14256181169027743\n",
            "training error = 0.14256181169027743\n",
            "tree 18 :\n",
            "\n",
            "training error = 0.09941698594214064\n",
            "training error = 0.09769733487411988\n",
            "training error = 0.09668359362937429\n",
            "training error = 0.09640788789000646\n",
            "training error = 0.09637611647557423\n",
            "training error = 0.09636733965834308\n",
            "tree 19 :\n",
            "\n",
            "training error = 0.1749033014559445\n",
            "training error = 0.1709587083052718\n",
            "training error = 0.16482709425505107\n",
            "training error = 0.15903198244012848\n",
            "training error = 0.15348074453507457\n",
            "training error = 0.14454633107606224\n",
            "tree 20 :\n",
            "\n",
            "training error = 0.20033977064240097\n",
            "training error = 0.19587399069689101\n",
            "training error = 0.18649688702282505\n",
            "training error = 0.1824133205717596\n",
            "training error = 0.17934828193214733\n",
            "training error = 0.1741111594318036\n",
            "0.07722437829560228\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracyRandomForest1 = RandomForest1.evaluateAccuracy(X_test, Y_test)\n",
        "accuracyRandomForest1 * 100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJ8btb73SHXe",
        "outputId": "c69c864a-05fd-4804-8639-4cbea04a18e9"
      },
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55.98493532012445"
            ]
          },
          "metadata": {},
          "execution_count": 250
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xQGg65Aw551Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}